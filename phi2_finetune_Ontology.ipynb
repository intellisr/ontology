{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9jFFHsuq6zi",
        "outputId": "ac7d3ea9-25bd-47b8-b8fa-dc02070fd8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQxgMZ32pzx-",
        "outputId": "5d5439d7-3e44-4c30-b16d-abdadf93ebaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash_attn\n",
            "  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.41.0)\n",
            "Collecting ninja (from flash_attn)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.5.8-cp310-cp310-linux_x86_64.whl size=120922965 sha256=13454dd3d37cf173649bd389b84614b8072fb283f8f2fd23a65ab66caafc304b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/5b/2b/dea8af4e954161c49ef1941938afcd91bb93689371ed12a226\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: ninja, xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, flash_attn, bitsandbytes, accelerate, peft\n",
            "Successfully installed accelerate-0.30.1 bitsandbytes-0.43.1 datasets-2.19.1 dill-0.3.8 einops-0.8.0 flash_attn-2.5.8 multiprocess-0.70.16 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "#Install the required packages for this project\n",
        "!pip install einops datasets bitsandbytes accelerate peft flash_attn\n",
        "# !pip uninstall -y transformers\n",
        "# !pip install git+https://github.com/huggingface/transformers\n",
        "# !pip install --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3e0e9b22faf34737804f31c3d7be06e1",
            "501573978f0346cd851df5a322585e2c",
            "d4c8cfb1b3064c25bfb20cea622ae9df",
            "2e2685ed6ae040fcadbe4ea12d5f5a8a",
            "f33296ae61a0491886647f4b115dd21b",
            "51986d69c66f4257ad25f7290e0d4717",
            "7edfd80f73b34b84b3d7d31283ffe216",
            "7ce2437e517f45e9834811a1bfa142c4",
            "6e864848db364bf39959c43f791ca300",
            "b9cbc86ca89b4463a8eb1ddb52ac9d27",
            "454fd47fa93f4d1c9e0e13e7435a7169"
          ]
        },
        "id": "jCpMhnh0hh0t",
        "outputId": "84596a18-4ec5-49aa-dcbd-a99a08dd7cc7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e0e9b22faf34737804f31c3d7be06e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "model_name = \"microsoft/phi-2\"\n",
        "\n",
        "# Configuration to load model in 4-bit quantized\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                bnb_4bit_quant_type='nf4',\n",
        "                                bnb_4bit_compute_dtype='float16',\n",
        "                                #bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                                bnb_4bit_use_double_quant=True)\n",
        "\n",
        "\n",
        "#Loading Microsoft's Phi-2 model with compatible settings\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto',\n",
        "                                             quantization_config=bnb_config,\n",
        "                                             #attn_implementation=\"flash_attention_2\",# to increase the training speed\n",
        "                                             trust_remote_code=True)\n",
        "\n",
        "# Setting up the tokenizer for Phi-2\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          add_eos_token=True,\n",
        "                                          trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.truncation_side = \"left\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekQqS_cHK71Y",
        "outputId": "bfb659fd-710d-426b-ca69-6d8e3a991a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory footprint: 1.792884736 GB\n"
          ]
        }
      ],
      "source": [
        "print(f\"Memory footprint: {model.get_memory_footprint() / 1e9} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-8tVjfSDXxj",
        "outputId": "4f720499-451b-4814-8ccd-727f6168a38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting py2neo\n",
            "  Downloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m174.1/177.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from py2neo) (2024.2.2)\n",
            "Collecting interchange~=2021.0.4 (from py2neo)\n",
            "  Downloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Collecting monotonic (from py2neo)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from py2neo) (24.0)\n",
            "Collecting pansi>=2020.7.3 (from py2neo)\n",
            "  Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.16.1)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.0.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from interchange~=2021.0.4->py2neo) (2023.4)\n",
            "Installing collected packages: monotonic, pansi, interchange, py2neo\n",
            "Successfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install py2neo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKOFoT1u75yO"
      },
      "outputs": [],
      "source": [
        "from py2neo import Graph, Node, Relationship\n",
        "graph = Graph(\"bolt+s://d0642942.databases.neo4j.io:7687\", auth=(\"neo4j\", \"AHHzMMC8_dusNm8T6bdkgs0lClYkdUg3VvChFi8d5GI\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVpqyLHqiJRj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Read the excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/ontology/uber.xlsx', header=None)\n",
        "train_dataset = Dataset.from_pandas(df[1:900])\n",
        "test_dataset = Dataset.from_pandas(df[900:1114])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfxu5YyaGjU5",
        "outputId": "8f58b1c6-a1ff-4afb-907b-8898d24bb138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0': 'How do I create an Uber account?',\n",
              " '1': \"Creating an Uber account requires a valid email address and phone number. You'll also need to create a password and agree to terms and conditions and our privacy notice.\\n\\nFill in your first and last name, phone number, and preferred language. Once you complete this part of the signup process, we send a text SMS to verify your phone number.\\n\\nNext, enter your payment information. Adding a credit card or debit card number allows your trip fares to be automatically charged after each ride. Please note that we cannot accept prepaid cards.\\n\\nAfter you provide this info, we'll send an email to confirm your account registration. Once you confirm, you'll be able to use your app to request a ride.\"}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxCYC0OPCQbf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    try:\n",
        "      text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "      text = re.sub(r'\\W', ' ', text)  # Remove non-alphanumeric characters\n",
        "      text = text.lower().strip()  # Convert to lowercase and strip spaces\n",
        "      return text\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3ca0tGgk1fZ"
      },
      "outputs": [],
      "source": [
        "def get_related_question(question):\n",
        "    query = \"\"\"\n",
        "    CALL db.index.fulltext.queryNodes(\"questionIndex\",$question)\n",
        "    YIELD node, score\n",
        "    RETURN node.name, score\n",
        "    ORDER BY score DESC\n",
        "    \"\"\"\n",
        "    result = graph.run(query, question=question).data()\n",
        "    return result[0]\n",
        "\n",
        "def get_related_data(action):\n",
        "    query = \"\"\"\n",
        "    MATCH (a:Action {name: $action})\n",
        "    OPTIONAL MATCH (a)-[:HAS_STEP]->(s:Step)\n",
        "    OPTIONAL MATCH (a)-[:HAS_REQUIREMENT]->(r:Requirement)\n",
        "    OPTIONAL MATCH (a)-[:HAS_KEY]->(k:Keys)\n",
        "    WITH a, collect(DISTINCT s.name) AS steps, collect(DISTINCT r.name) AS requirements, collect(DISTINCT k.name) AS keys\n",
        "    RETURN steps, requirements, keys\n",
        "    \"\"\"\n",
        "    result = graph.run(query, action=action).data()\n",
        "    return result[0]\n",
        "\n",
        "def get_action(question):\n",
        "    query = \"\"\"\n",
        "    MATCH (q:Question {name: $question})<-[:HAS_QUESTION]-(a:Action)\n",
        "    RETURN a.name AS action\n",
        "    \"\"\"\n",
        "    result = graph.run(query, question=question).data()\n",
        "    return result[0]\n",
        "\n",
        "\n",
        "def get_context(q_txt):\n",
        "    related_data = get_related_question(q_txt)\n",
        "\n",
        "    action=get_action(related_data['node.name'])\n",
        "\n",
        "    related_data = get_related_data(action['action'])\n",
        "\n",
        "    key_txt=\"#Key words:\"\n",
        "    keys=related_data['keys']\n",
        "    for k in keys:\n",
        "        key_txt=key_txt+k+','\n",
        "\n",
        "    req_txt=\"#Prerequisites:\"\n",
        "    requirements=related_data['requirements']\n",
        "    for r in requirements:\n",
        "        req_txt=req_txt+r+','\n",
        "\n",
        "    step_txt=\"#Steps to Follow:\"\n",
        "    steps=related_data['steps']\n",
        "    for s in steps:\n",
        "        step_txt=step_txt+s+','\n",
        "\n",
        "    context=key_txt+'\\n'+req_txt+'\\n'+step_txt\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjiMMZ-gkotJ"
      },
      "outputs": [],
      "source": [
        "#Function that creates a prompt from instruction, context, category and response and tokenizes it\n",
        "def collate_and_tokenize(examples):\n",
        "\n",
        "    question=examples['0'][0]\n",
        "    answer=examples['1'][0]\n",
        "    q_text=preprocess_text(question)\n",
        "    if q_text:\n",
        "      context=get_context(q_text)\n",
        "    else:\n",
        "      context=\"No Context\"\n",
        "\n",
        "    #Merging into one prompt for tokenization and training\n",
        "    prompt = f\"\"\"###System:Read the Context provided and answer the corresponding question.\n",
        "    ###Context:\n",
        "    {context}\n",
        "    ###Question:\n",
        "    {question}\n",
        "    ###Answer:\n",
        "    {answer}\"\"\"\n",
        "\n",
        "    #Tokenize the prompt\n",
        "    encoded = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"np\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        ## Very critical to keep max_length at 1024.\n",
        "        ## Anything more will lead to OOM on T4\n",
        "        max_length=2048,\n",
        "    )\n",
        "\n",
        "    encoded[\"labels\"] = encoded[\"input_ids\"]\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "cff5cc9f46594754b6033598ae115271",
            "863ae630822e44c88601837beda888bf",
            "97f6d72947324af2af7fb57fc4df99b2",
            "38cec2afc4ec47ad8a3105c2511ea800",
            "fc8fd8e1710447cf9f954a18ae605d1e",
            "eb26f39ccf4f428685af82193173aa62",
            "4dafa80730994feabcdd9b985e91f024",
            "f9a7fb2642e647f7a7c3c91832d94539",
            "490d97e500674dea99224a7315718958",
            "83bf79a33a7c496a80d043c94ca36c9c",
            "80dac9e384ac40a4a148d7426fdeb146",
            "a229daae38e64bdf997d730b2f0b03fd",
            "e7c58a5e27b14d5dbe1cbc9bff0d17fa",
            "bb520c6f55eb41208db75c2d9dec6939",
            "6ccf53d32b1640beb6759ee6895964ee",
            "4acf32a31f2b4fdabd520747592d6e34",
            "defc3d01e2d04dfeafcffff970a2219e",
            "fae420519b9a4ccda46fd6af01d4e047",
            "b7ec43e5da2d42e29df152e28ea13392",
            "51476c105a794eb9b25bf991822c0dd3",
            "ce40c93600b74406a953cc89b6fa3632",
            "cb697b776a68462399a67bc99f198414"
          ]
        },
        "id": "RZLVRL2Wk3vj",
        "outputId": "befcf5d1-cffc-42c4-9b16-02e8fcd958a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parameter 'function'=<function collate_and_tokenize at 0x7bf4a9188d30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function collate_and_tokenize at 0x7bf4a9188d30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cff5cc9f46594754b6033598ae115271",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/899 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected string or bytes-like object\n",
            "expected string or bytes-like object\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a229daae38e64bdf997d730b2f0b03fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "expected string or bytes-like object\n",
            "expected string or bytes-like object\n",
            "expected string or bytes-like object\n"
          ]
        }
      ],
      "source": [
        "#We will just keep the input_ids and labels that we add in function above.\n",
        "columns_to_remove = ['0','1']\n",
        "\n",
        "# tokenize the training and test datasets\n",
        "tokenized_dataset_train = train_dataset.map(collate_and_tokenize,\n",
        "                                            batched=True,\n",
        "                                            batch_size=1,\n",
        "                                            remove_columns=columns_to_remove)\n",
        "tokenized_dataset_test = test_dataset.map(collate_and_tokenize,\n",
        "                                          batched=True,\n",
        "                                          batch_size=1,\n",
        "                                          remove_columns=columns_to_remove)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tez7pYN4jqTF",
        "outputId": "ef0daf51-1456-4a92-93ee-0edd8881d068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###System:Read the Context and Chat History provided and answer the corresponding question.\n",
            "    ###Context:\n",
            "    #Key words:\n",
            "#Prerequisites:Valid email address,Password,Agreement to terms and conditions,Agreement to privacy notice,First and last name,Payment information (credit card or debit card),Verification of phone number via SMS/text message,\n",
            "#Steps to Follow:Create a valid email address,Get a valid phone number,Create a password,Agree to terms and conditions and our privacy notice,Fill in your first and last name,Phone number,Preferred language,Complete the signup process,Receive a text SMS to verify your phone number,Enter payment information (credit card or debit card),Confirm account registration via email,Use the app to request a ride,\n",
            "    ###Question:\n",
            "    Please help me create an uber account\n",
            "    ###Answer:\n",
            "    Creating an Uber account requires a valid email address and phone number. You'll also need to create a password and agree to terms and conditions and our privacy notice.\n",
            "\n",
            "Fill in your first and last name, phone number, and preferred language. Once you complete this part of the signup process, we send a text SMS to verify your phone number.\n",
            "\n",
            "Next, enter your payment information. Adding a credit card or debit card number allows your trip fares to be automatically charged after each ride. Please note that we cannot accept prepaid cards.\n",
            "\n",
            "After you provide this info, we'll send an email to confirm your account registration. Once you confirm, you'll be able to use your app to request a ride.\n"
          ]
        }
      ],
      "source": [
        "#Check if tokenization looks good\n",
        "input_ids = tokenized_dataset_train[2]['input_ids']\n",
        "\n",
        "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB9NMBzasFcT"
      },
      "outputs": [],
      "source": [
        "#Accelerate training models on larger batch sizes, we can use a fully sharded data parallel model.\n",
        "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
        "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
        "\n",
        "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
        "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dipMfTbgPvoM"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uamQX0JVvoGF",
        "outputId": "d9769afa-edc3-439a-ab7b-d9ab749698ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 262364160 || all params: 1521392640 || trainable%: 17.24\n",
            "PhiForCausalLM(\n",
            "  (model): PhiModel(\n",
            "    (embed_tokens): Embedding(51200, 2560)\n",
            "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x PhiDecoderLayer(\n",
            "        (self_attn): PhiFlashAttention2(\n",
            "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
            "          (rotary_emb): PhiRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): PhiMLP(\n",
            "          (activation_fn): NewGELUActivation()\n",
            "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
            "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
            "        )\n",
            "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "print_trainable_parameters(model)\n",
        "\n",
        "#gradient checkpointing to save memory\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Freeze base model layers and cast layernorm in fp32\n",
        "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PuVk7YBwxY9",
        "outputId": "c303f7b1-ee4c-40b4-e057-2b9a8e472d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 23592960 || all params: 1544985600 || trainable%: 1.53\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "    'q_proj',\n",
        "    'k_proj',\n",
        "    'v_proj',\n",
        "    'dense',\n",
        "    'fc1',\n",
        "    'fc2',\n",
        "    ], #print(model) will show the modules to use\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, config)\n",
        "print_trainable_parameters(lora_model)\n",
        "\n",
        "\n",
        "lora_model = accelerator.prepare_model(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0WaZpJhhvp"
      },
      "source": [
        "### Training the Model and saving to Hub\n",
        "This is where, we setup the training arguments. These arguments have been carefully selected to improve memory utilization and also help increase performance. I played around with these for a while, before finalizing the following arguments.\n",
        "\n",
        "Finally, I am saving the model weights , so we do not loose out work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8XL28nNu_QG",
        "outputId": "376f14f7-dac7-4d08-f3d2-632232199b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ontology/phi2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ontology/phi2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m2T1Q6Zz9k3H",
        "outputId": "0e00f632-0d59-4367-b28f-5138c4ff2b8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 3:17:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.820100</td>\n",
              "      <td>0.485170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.609600</td>\n",
              "      <td>0.471045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.589800</td>\n",
              "      <td>0.466512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.581600</td>\n",
              "      <td>0.465981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.555800</td>\n",
              "      <td>0.467200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.543400</td>\n",
              "      <td>0.469741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.531600</td>\n",
              "      <td>0.475205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.517300</td>\n",
              "      <td>0.478684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.500800</td>\n",
              "      <td>0.480893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.490400</td>\n",
              "      <td>0.489742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.469900</td>\n",
              "      <td>0.489646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.468300</td>\n",
              "      <td>0.492276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.462800</td>\n",
              "      <td>0.495493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.459200</td>\n",
              "      <td>0.498595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.446700</td>\n",
              "      <td>0.500248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.444300</td>\n",
              "      <td>0.497432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.437700</td>\n",
              "      <td>0.501456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.441000</td>\n",
              "      <td>0.501847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed in 11856.731600522995 seconds.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Output directory for checkpoints and predictions\n",
        "    overwrite_output_dir=True, # Overwrite the content of the output directory\n",
        "    per_device_train_batch_size=2,  # Batch size for training\n",
        "    per_device_eval_batch_size=2,  # Batch size for evaluation\n",
        "    gradient_accumulation_steps=5, # number of steps before optimizing\n",
        "    gradient_checkpointing=True,   # Enable gradient checkpointing\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    warmup_steps=50,  # Number of warmup steps\n",
        "    #max_steps=1000,  # Total number of training steps\n",
        "    num_train_epochs=2,  # Number of training epochs\n",
        "    learning_rate=5e-5,  # Learning rate\n",
        "    weight_decay=0.01,  # Weight decay\n",
        "    optim=\"paged_adamw_8bit\", #Keep the optimizer state and quantize it\n",
        "    fp16=True, #Use mixed precision training\n",
        "    #For logging and saving\n",
        "    logging_dir='./logs',\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,  # Limit the total number of checkpoints\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    load_best_model_at_end=True, # Load the best model at the end of training\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    train_dataset=tokenized_dataset_train,\n",
        "    eval_dataset=tokenized_dataset_test,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "#Disable cache to prevent warning, renable for inference\n",
        "model.config.use_cache = False\n",
        "\n",
        "start_time = time.time()  # Record the start time\n",
        "trainer.train()  # Start training\n",
        "end_time = time.time()  # Record the end time\n",
        "\n",
        "training_time = end_time - start_time  # Calculate total training time\n",
        "\n",
        "print(f\"Training completed in {training_time} seconds.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YtMG1_KayQp",
        "outputId": "9b5ed78c-aa56-4364-9687-81b673b7a565"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Save model to drive to ensure we save our work.\n",
        "trainer.save_model(\"result/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-EnOhwkcG7ea",
        "outputId": "e015974a-6702-4f43-b8c8-39e4d89e9cd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4659807085990906, 'eval_runtime': 19.1522, 'eval_samples_per_second': 5.221, 'eval_steps_per_second': 2.611, 'epoch': 2.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lGFO4hSY1RD"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hFerF5h-nQS"
      },
      "source": [
        "## Run Inference\n",
        "\n",
        "**Note**: Ensure to stop your session and reconnect and reload the model before running the code below.\n",
        "\n",
        "First we will run inference without the trained weights and check the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On4l4ueKu0PU"
      },
      "source": [
        "Next, lets run the model with lora config and check inference on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqLh4Qocuzc9"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "#Load the model weights from hub\n",
        "model_id = \"result/\"\n",
        "trained_model = PeftModel.from_pretrained(model, model_id)\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QS_GkxJO2jF"
      },
      "source": [
        "## Calculate F1 Score\n",
        "\n",
        "**Note**: Run all the cells to find average f1 score of test data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRYf2Wl3EARt"
      },
      "outputs": [],
      "source": [
        "import re, string\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "    #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyzI8rCLFyDV"
      },
      "outputs": [],
      "source": [
        "def spliit_and_return(txt):\n",
        "  parts=txt.split(\"###Answer:\")\n",
        "  return parts[0],parts[1]\n",
        "\n",
        "  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYpWMp-aBR4A",
        "outputId": "3b643459-9772-4c06-9277-8e0e6efa5a9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:   0%|          | 0/10 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Loading...:  10%|█         | 1/10 [00:14<02:09, 14.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can.\n",
            "\n",
            "To contact your driver, you can:\n",
            "\n",
            "1. Tap the single tap icon on the top right corner of the screen.\n",
            "2. Double tap the round phone icon under your driver's information.\n",
            "3. Double tap the phone number or the 'Free Call' button.\n",
            "4. Your phone will automatically call your driver according to the option you chose.\n",
            "0.4814814814814815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  20%|██        | 2/10 [00:31<02:06, 15.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can communicate with your driver using TalkBack.\n",
            "\n",
            "To do this, you need to be matched with a driver. Once you are matched, you can single tap the round phone icon under your driver's information.\n",
            "\n",
            "Next, double tap the phone number or the 'Free Call' button. Your phone will automatically call your driver according to the option you chose.\n",
            "0.4121212121212121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  30%|███       | 3/10 [00:42<01:34, 13.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can.\n",
            "\n",
            "To get in touch with your driver, you can:\n",
            "\n",
            "1. Tap the single tap icon next to your driver's name.\n",
            "2. Double tap the round phone icon under your driver's information.\n",
            "3. Double tap the phone number or the 'Free Call' button.\n",
            "\n",
            "Your phone will automatically call your driver according to the option you chose.\n",
            "0.5030674846625768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  40%|████      | 4/10 [00:57<01:25, 14.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can contact your Uber driver using the TalkBack feature.\n",
            "\n",
            "To use TalkBack, you need to be matched with a driver. Once you’re matched, you can contact your driver by:\n",
            "\n",
            "1. Single tap the round phone icon under your driver’s information.\n",
            "2. Double tap the phone number or the “Free Call” button.\n",
            "3. Your phone will automatically call your driver according to the option you chose.\n",
            "\n",
            "If you’re not matched with a driver, you can still contact them using the Uber app.\n",
            "0.4432432432432432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  50%|█████     | 5/10 [01:08<01:05, 13.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can.\n",
            "\n",
            "To reach out to your driver, you can:\n",
            "\n",
            "1. Tap the single tap icon on the top right corner of the screen.\n",
            "2. Double tap the round phone icon under your driver's information.\n",
            "3. Double tap the phone number or the 'Free Call' button.\n",
            "4. Your phone will automatically call your driver according to the option you chose.\n",
            "0.48780487804878053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  60%|██████    | 6/10 [01:20<00:50, 12.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can talk to your Uber driver using TalkBack.\n",
            "\n",
            "To do so, follow these steps:\n",
            "\n",
            "1. Tap the single tap icon on the top right corner of the screen.\n",
            "2. Double tap the round phone icon under your driver's information.\n",
            "3. Double tap the phone number or the 'Free Call' button.\n",
            "4. Your phone will automatically call your driver according to the option you chose.\n",
            "0.47337278106508873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  70%|███████   | 7/10 [01:32<00:37, 12.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    Yes, you can.\n",
            "\n",
            "To contact your driver, you can:\n",
            "\n",
            "1. Tap the “Uber” app icon.\n",
            "2. Tap the “Uber” app icon.\n",
            "3. Double tap the round phone icon under your driver’s information.\n",
            "4. Double tap the phone number or the “Free Call” button.\n",
            "5. Your phone will automatically call your driver according to the option you chose.\n",
            "0.47204968944099374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  80%|████████  | 8/10 [05:30<02:48, 84.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    To request a ride with TalkBack, follow these steps:\n",
            "\n",
            "1. Tap the “Where to” button.\n",
            "2. Select your destination.\n",
            "3. Tap the “Confirm pickup” button.\n",
            "4. Wait for the driver to arrive.\n",
            "5. When the driver arrives, tap the “Where to” button again.\n",
            "6. Select your destination.\n",
            "7. Tap the “Confirm pickup” button.\n",
            "8. Wait for the driver to arrive.\n",
            "9. When the driver arrives, tap the “Where to” button again.\n",
            "10. Select your destination.\n",
            "11. Tap the “Confirm pickup” button.\n",
            "12. Wait for the driver to arrive.\n",
            "13. When the driver arrives, tap the “Where to” button again.\n",
            "14. Select your destination.\n",
            "15. Tap the “Confirm pickup” button.\n",
            "16. Wait for the driver to arrive.\n",
            "17. When the driver arrives, tap the “Where to” button again.\n",
            "18. Select your destination.\n",
            "19. Tap the “Confirm pickup” button.\n",
            "20. Wait for the driver to arrive.\n",
            "21. When the driver arrives, tap the “Where to” button again.\n",
            "22. Select your destination.\n",
            "23. Tap the “Confirm pickup” button.\n",
            "24. Wait for the driver to arrive.\n",
            "25. When the driver arrives, tap the “Where to” button again.\n",
            "26. Select your destination.\n",
            "27. Tap the “Confirm pickup” button.\n",
            "28. Wait for the driver to arrive.\n",
            "29. When the driver arrives, tap the “Where to” button again.\n",
            "30. Select your destination.\n",
            "31. Tap the “Confirm pickup” button.\n",
            "32. Wait for the driver to arrive.\n",
            "33. When the driver arrives, tap the “Where to” button again.\n",
            "34. Select your destination.\n",
            "35. Tap the “Confirm pickup” button.\n",
            "36. Wait for the driver to arrive.\n",
            "37. When the driver arrives, tap the “Where to” button again.\n",
            "38. Select your destination.\n",
            "39. Tap the “Confirm pickup” button.\n",
            "40. Wait for the driver to arrive.\n",
            "41. When the driver arrives, tap the “Where to” button again.\n",
            "42. Select your destination.\n",
            "43. Tap the “Confirm pickup” button.\n",
            "44. Wait for the driver to arrive.\n",
            "45. When the driver arrives, tap the “Where to” button again.\n",
            "46. Select your destination.\n",
            "47. Tap the “Confirm pickup” button.\n",
            "48. Wait for the driver to arrive.\n",
            "49. When the driver arrives, tap the “Where to” button again.\n",
            "50. Select your destination.\n",
            "51. Tap the “Confirm pickup” button.\n",
            "52. Wait for the driver to arrive.\n",
            "53. When the driver arrives, tap the “Where to” button again.\n",
            "54. Select your destination.\n",
            "55. Tap the “Confirm pickup” button.\n",
            "56. Wait for the driver to arrive.\n",
            "57. When the driver arrives, tap the “Where to” button again.\n",
            "58. Select your destination.\n",
            "59. Tap the “Confirm pickup” button.\n",
            "60. Wait for the driver to arrive.\n",
            "61. When the driver arrives, tap the “Where to” button again.\n",
            "62. Select your destination.\n",
            "63. Tap the “Confirm pickup” button.\n",
            "64. Wait for the driver to arrive.\n",
            "65. When the driver arrives, tap the “Where to” button again.\n",
            "66. Select your destination.\n",
            "67. Tap the “Confirm pickup” button.\n",
            "68. Wait for the driver to arrive.\n",
            "69. When the driver arrives, tap the “Where to” button again.\n",
            "70. Select your destination.\n",
            "71. Tap the “Confirm pickup” button.\n",
            "72. Wait for the driver to arrive.\n",
            "73. When the driver arrives, tap the “Where to” button again.\n",
            "74. Select your destination.\n",
            "75. Tap the “Confirm pickup” button.\n",
            "76. Wait for the driver to arrive.\n",
            "77. When the driver arrives, tap the “Where to” button again.\n",
            "78. Select your destination.\n",
            "79. Tap the “Confirm pickup” button.\n",
            "80. Wait for the driver to arrive.\n",
            "81. When the driver arrives, tap the “Where to” button again.\n",
            "82. Select your destination.\n",
            "83. Tap the “Confirm pickup” button.\n",
            "84. Wait for the driver to arrive.\n",
            "85. When the driver arrives, tap the “Where to” button again.\n",
            "86. Select your destination.\n",
            "87. Tap the “Confirm pickup” button.\n",
            "88. Wait for the driver to arrive.\n",
            "89. When the driver arrives, tap the “Where to” button again.\n",
            "90. Select your destination.\n",
            "91. Tap the “Confirm pickup” button.\n",
            "92. Wait for the driver to arrive.\n",
            "93. When the driver arrives, tap the “Where to” button again.\n",
            "94. Select your destination.\n",
            "95. Tap the “Confirm pickup” button.\n",
            "96. Wait for the driver to arrive.\n",
            "97. When the driver arrives, tap the “Where to” button again.\n",
            "98. Select your destination.\n",
            "99. Tap the “Confirm pickup” button.\n",
            "100. Wait for the driver to arrive.\n",
            "101. When the driver arrives, tap the “Where to” button again.\n",
            "102. Select your destination.\n",
            "103. Tap the “Confirm pickup” button.\n",
            "104. Wait for the driver to arrive.\n",
            "105. When the driver arrives, tap the “Where to” button again.\n",
            "106. Select your destination.\n",
            "107. Tap the “Confirm pickup” button.\n",
            "108. Wait for the driver to arrive.\n",
            "109. When the driver arrives, tap the “Where to” button again.\n",
            "110. Select your destination.\n",
            "111. Tap the “Confirm pickup” button.\n",
            "112. Wait for the driver to arrive.\n",
            "113. When the driver arrives, tap the “Where to” button again.\n",
            "114. Select your destination.\n",
            "115. Tap the “Confirm pickup” button.\n",
            "116. Wait for the driver to arrive.\n",
            "117. When the driver arrives, tap the “Where to” button again.\n",
            "118. Select your destination.\n",
            "119. Tap the “Confirm pickup” button.\n",
            "120. Wait for the driver to arrive.\n",
            "121. When the driver arrives, tap the “Where to” button again.\n",
            "122. Select your destination.\n",
            "123. Tap the “Confirm pickup” button.\n",
            "124. Wait for the driver to arrive.\n",
            "125. When the driver arrives, tap the “Where to” button again.\n",
            "126. Select your destination.\n",
            "127. Tap the “Confirm pickup” button.\n",
            "128. Wait for the driver to arrive.\n",
            "129. When the driver arrives, tap the “Where to” button again.\n",
            "130. Select your destination.\n",
            "131. Tap the “Confirm pickup” button.\n",
            "132. Wait for the driver to arrive.\n",
            "133. When the driver arrives, tap the “Where to” button again.\n",
            "134. Select your destination.\n",
            "135. Tap the “Confirm pickup” button.\n",
            "136. Wait for the driver to arrive.\n",
            "137. When the driver arrives, tap the “Where to” button again.\n",
            "138. Select your destination.\n",
            "139. Tap the “Confirm pickup” button.\n",
            "140. Wait for the driver to arrive.\n",
            "141. When the driver arrives, tap the “Where to” button again.\n",
            "142. Select your destination.\n",
            "143. Tap the “Confirm pickup” button.\n",
            "144. Wait for the driver to arrive.\n",
            "145. When the driver arrives, tap the “Where to” button again.\n",
            "146. Select your destination.\n",
            "147. Tap the “Confirm pickup” button.\n",
            "148. Wait for the driver to arrive.\n",
            "149. When the driver arrives, tap the “Where to” button again.\n",
            "150. Select your destination.\n",
            "151. Tap the “Confirm pickup” button.\n",
            "152. Wait for the driver to arrive.\n",
            "153. When the driver arrives, tap the “Where to” button again.\n",
            "154. Select your destination.\n",
            "155. Tap the “Confirm pickup” button.\n",
            "156. Wait for the driver to arrive.\n",
            "0.1288076588337685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rLoading...:  90%|█████████ | 9/10 [09:29<02:12, 132.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    To request an Uber ride using TalkBack, follow these steps:\n",
            "\n",
            "1. Tap the “Where to” button.\n",
            "2. Select your destination.\n",
            "3. Tap the “Confirm pickup” button.\n",
            "4. If you’re using a phone with a touch screen, double tap the “Where to” button.\n",
            "5. If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "6. Confirm your pickup location by tapping the “Confirm pickup” button.\n",
            "7. If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "8. If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "9. Confirm your pickup location by tapping the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a touch screen, double tap the “Where to” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup” button.\n",
            "\n",
            "If you’re using a phone with a physical keyboard, swipe through vehicle options.\n",
            "\n",
            "If you’re using a phone with a touch screen, tap the “Confirm pickup\n",
            "0.10801393728222997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading...: 100%|██████████| 10/10 [09:46<00:00, 58.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction \n",
            "    When you request a ride with TalkBack, you'll see a map of your location.\n",
            "\n",
            "1. Tap where to go.\n",
            "2. Double tap to confirm your destination.\n",
            "3. Swipe through vehicle options.\n",
            "4. Confirm pickup button.\n",
            "5. Your driver will arrive at your location.\n",
            "\n",
            "If you're using TalkBack, you'll see a map of your location.\n",
            "\n",
            "1. Tap where to go.\n",
            "2. Double tap to confirm your destination.\n",
            "3. Swipe through vehicle options.\n",
            "4. Confirm pickup button.\n",
            "5. Your driver will arrive at your location.\n",
            "0.3529411764705882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Calculate Average L1 score for the trained model\n",
        "from tqdm import tqdm\n",
        "\n",
        "all_f1=[]\n",
        "for i in tqdm (range (10), desc=\"Loading...\"):\n",
        "  input_ids = tokenized_dataset_test[i]['input_ids']\n",
        "  decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
        "  qustion_txt, ground_truth = spliit_and_return(decoded)\n",
        "  # print(\"real\",ground_truth)\n",
        "\n",
        "  inputs = tokenizer(qustion_txt, return_tensors=\"pt\",\n",
        "                   return_attention_mask=False,\n",
        "                   padding=True, truncation=True)\n",
        "  inputs.to('cuda')\n",
        "  outputs = trained_model.generate(**inputs, max_length=2048)\n",
        "  out_put_text = tokenizer.batch_decode(outputs,skip_special_tokens=True)[0]\n",
        "  qustion_txt, prediction = spliit_and_return(out_put_text)\n",
        "  print(\"prediction\",prediction)\n",
        "\n",
        "  f1=f1_score(prediction, ground_truth)\n",
        "  print(f1)\n",
        "  all_f1.append(f1)\n",
        "\n",
        "  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JYwq53jNLi-",
        "outputId": "67e0a0d4-9d3f-445e-ac1f-3e1515f14c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Score For Testing:  38.629035426499634\n"
          ]
        }
      ],
      "source": [
        "# average F1 score for test data set\n",
        "avg_F1=sum(all_f1) / len(all_f1)\n",
        "print(\"Average Score For Testing: \",avg_F1*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e2685ed6ae040fcadbe4ea12d5f5a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9cbc86ca89b4463a8eb1ddb52ac9d27",
            "placeholder": "​",
            "style": "IPY_MODEL_454fd47fa93f4d1c9e0e13e7435a7169",
            "value": " 2/2 [00:25&lt;00:00, 11.10s/it]"
          }
        },
        "38cec2afc4ec47ad8a3105c2511ea800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bf79a33a7c496a80d043c94ca36c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_80dac9e384ac40a4a148d7426fdeb146",
            "value": " 899/899 [07:28&lt;00:00,  2.03 examples/s]"
          }
        },
        "3e0e9b22faf34737804f31c3d7be06e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_501573978f0346cd851df5a322585e2c",
              "IPY_MODEL_d4c8cfb1b3064c25bfb20cea622ae9df",
              "IPY_MODEL_2e2685ed6ae040fcadbe4ea12d5f5a8a"
            ],
            "layout": "IPY_MODEL_f33296ae61a0491886647f4b115dd21b"
          }
        },
        "454fd47fa93f4d1c9e0e13e7435a7169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "490d97e500674dea99224a7315718958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4acf32a31f2b4fdabd520747592d6e34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dafa80730994feabcdd9b985e91f024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501573978f0346cd851df5a322585e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51986d69c66f4257ad25f7290e0d4717",
            "placeholder": "​",
            "style": "IPY_MODEL_7edfd80f73b34b84b3d7d31283ffe216",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "51476c105a794eb9b25bf991822c0dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51986d69c66f4257ad25f7290e0d4717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccf53d32b1640beb6759ee6895964ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce40c93600b74406a953cc89b6fa3632",
            "placeholder": "​",
            "style": "IPY_MODEL_cb697b776a68462399a67bc99f198414",
            "value": " 214/214 [01:44&lt;00:00,  2.12 examples/s]"
          }
        },
        "6e864848db364bf39959c43f791ca300": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ce2437e517f45e9834811a1bfa142c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7edfd80f73b34b84b3d7d31283ffe216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80dac9e384ac40a4a148d7426fdeb146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83bf79a33a7c496a80d043c94ca36c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863ae630822e44c88601837beda888bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb26f39ccf4f428685af82193173aa62",
            "placeholder": "​",
            "style": "IPY_MODEL_4dafa80730994feabcdd9b985e91f024",
            "value": "Map: 100%"
          }
        },
        "97f6d72947324af2af7fb57fc4df99b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a7fb2642e647f7a7c3c91832d94539",
            "max": 899,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_490d97e500674dea99224a7315718958",
            "value": 899
          }
        },
        "a229daae38e64bdf997d730b2f0b03fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c58a5e27b14d5dbe1cbc9bff0d17fa",
              "IPY_MODEL_bb520c6f55eb41208db75c2d9dec6939",
              "IPY_MODEL_6ccf53d32b1640beb6759ee6895964ee"
            ],
            "layout": "IPY_MODEL_4acf32a31f2b4fdabd520747592d6e34"
          }
        },
        "b7ec43e5da2d42e29df152e28ea13392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cbc86ca89b4463a8eb1ddb52ac9d27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb520c6f55eb41208db75c2d9dec6939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ec43e5da2d42e29df152e28ea13392",
            "max": 214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51476c105a794eb9b25bf991822c0dd3",
            "value": 214
          }
        },
        "cb697b776a68462399a67bc99f198414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce40c93600b74406a953cc89b6fa3632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff5cc9f46594754b6033598ae115271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_863ae630822e44c88601837beda888bf",
              "IPY_MODEL_97f6d72947324af2af7fb57fc4df99b2",
              "IPY_MODEL_38cec2afc4ec47ad8a3105c2511ea800"
            ],
            "layout": "IPY_MODEL_fc8fd8e1710447cf9f954a18ae605d1e"
          }
        },
        "d4c8cfb1b3064c25bfb20cea622ae9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ce2437e517f45e9834811a1bfa142c4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e864848db364bf39959c43f791ca300",
            "value": 2
          }
        },
        "defc3d01e2d04dfeafcffff970a2219e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c58a5e27b14d5dbe1cbc9bff0d17fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_defc3d01e2d04dfeafcffff970a2219e",
            "placeholder": "​",
            "style": "IPY_MODEL_fae420519b9a4ccda46fd6af01d4e047",
            "value": "Map: 100%"
          }
        },
        "eb26f39ccf4f428685af82193173aa62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33296ae61a0491886647f4b115dd21b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a7fb2642e647f7a7c3c91832d94539": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae420519b9a4ccda46fd6af01d4e047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc8fd8e1710447cf9f954a18ae605d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
